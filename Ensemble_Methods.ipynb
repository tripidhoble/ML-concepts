{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>434</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "9590   37    1        1          1        0      740        1     0        0   \n",
       "5852   30    9        2          1        0      411        1     0        0   \n",
       "8298   42    4        0          2        0     1064        0     0        0   \n",
       "9068   47    9        1          1        0     2246        1     0        0   \n",
       "3454   63    1        1          0        0      115        0     0        1   \n",
       "\n",
       "      day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "9590    7      8       434         3    342         2         0        0  \n",
       "5852   16      0       948         1     -1         0         3        0  \n",
       "8298   18      1       101         2     -1         0         3        0  \n",
       "9068   10      5       330         1     -1         0         3        0  \n",
       "3454   27      0       325         1    180         7         0        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/ensemble.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('deposit', axis = 1)\n",
    "y = data['deposit'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Aggregation: Soft Voting & Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard_voting_score:  0.7709764108689161\n",
      "soft_voting_score:  0.787996416840848\n"
     ]
    }
   ],
   "source": [
    "#Different models initialised\n",
    "log_clf_1 = LogisticRegression(random_state=0)\n",
    "log_clf_2 = LogisticRegression(random_state=42)\n",
    "decision_clf1 = DecisionTreeClassifier(criterion = 'entropy',random_state=0)\n",
    "decision_clf2 = DecisionTreeClassifier(criterion = 'entropy', random_state=42)\n",
    "\n",
    "\n",
    "#Creation of list of models\n",
    "Model_List=[('Logistic Regression 1', log_clf_1),\n",
    "            ('Logistic Regression 2', log_clf_2),\n",
    "            ('Decision Tree 1', decision_clf1),\n",
    "            ('Decision Tree 2', decision_clf2)]\n",
    "\n",
    "voting_clf_hard = VotingClassifier(estimators = Model_List, voting = 'hard')\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "hard_voting_score = voting_clf_hard.score(X_test, y_test)\n",
    "print(\"hard_voting_score: \", hard_voting_score)\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators = Model_List, voting = 'soft')\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "soft_voting_score = voting_clf_soft.score(X_test, y_test)\n",
    "print(\"soft_voting_score: \", soft_voting_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Aggregation(Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_bagging:  0.8139743206927441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 100,\\\n",
    "                                max_samples = 100, random_state = 0)\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "score_bagging = bagging_clf.score(X_test, y_test)\n",
    "print(\"score_bagging: \", score_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting\n",
    "## we can create samples resampling without replacement for each base learner. Ensemble on such samples is known as Pasting.\n",
    "### (Python implementation of pasting is same as bagging with an added parameter of changing \"bootstrap=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_pasting:  0.8112869513287548\n"
     ]
    }
   ],
   "source": [
    "pasting_clf = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 100, \\\n",
    "                                max_samples = 100, bootstrap = False, random_state = 0)\n",
    "\n",
    "pasting_clf.fit(X_train, y_train)\n",
    "score_pasting = pasting_clf.score(X_test, y_test)\n",
    "print(\"score_pasting: \", score_pasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Definition:\n",
    "### Random forest is an ensemble method of bagging multiple decision trees. The fundamental difference is that in Random Forests, along with bootstrap sampling, only a subset of features are selected at random out of the total features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_rf:  0.8220364287847118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, n_jobs = 100, min_samples_leaf = 100, random_state = 0)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "score_rf = rf_clf.score(X_test, y_test)\n",
    "print(\"score_rf: \", score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_gs:  0.8369662585846521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Parameter grid\n",
    "parameter_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = parameter_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "score_gs = grid_search.score(X_test, y_test)\n",
    "print(\"score_gs: \", score_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_rs:  0.8384592415646461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = clf, param_distributions = parameter_grid, n_iter = 20, random_state= 0 )\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "score_rs = random_search.score(X_test, y_test)\n",
    "print(\"score_rs: \", score_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_score:  0.7751567632128994\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "classifier1 = DecisionTreeClassifier(random_state=0)\n",
    "classifier2= DecisionTreeClassifier(random_state=1)\n",
    "classifier3 = DecisionTreeClassifier(random_state=2)\n",
    "classifier4= DecisionTreeClassifier(random_state=3)\n",
    "classifier_list=[classifier1,classifier2,classifier3,classifier4]\n",
    "\n",
    "m_classifier=LogisticRegression(random_state=0)\n",
    "\n",
    "sclf = StackingClassifier(classifiers = classifier_list, meta_classifier = m_classifier)\n",
    "sclf.fit(X_train, y_train)\n",
    "\n",
    "s_score = sclf.score(X_test, y_test)\n",
    "print(\"s_score: \", s_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
